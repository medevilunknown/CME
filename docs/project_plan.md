## Project: Development and Implementation of a Physics-Informed Generative Anomaly Detection System with Explainable AI (PIGADE-X) for Real-time Halo CME Identification using Aditya-L1 SWIS-ASPEX Data

This project aims to build an advanced AI system that can autonomously detect halo Coronal Mass Ejection (CME) events using particle data from the Solar Wind Ion Spectrometer (SWIS) and Supra Thermal & Energetic Particle Spectrometer (STEPS) subsystems of the ASPEX payload onboard India's Aditya-L1 mission. The innovation lies in using generative models for anomaly detection (learning "normal" solar wind), integrating physics-informed constraints, and providing explainable AI (XAI) insights into its detections.

---

### Project Goal:

To develop, validate, and deploy an explainable, physics-informed AI system capable of real-time detection and characterization of halo CME events (including associated shocks and ejecta) by identifying anomalies in Aditya-L1 SWIS-ASPEX particle data, thereby enhancing space weather forecasting capabilities.

### Steps to Do It:

#### Phase 1: Project Setup and Data Preparation (Months 1-3)

1.  **Define Detailed Requirements & Success Metrics:**
    * **Sub-steps:**
        * Formalize the types of CMEs/ICMEs to be detected (full/partial halo, magnetic cloud, sheath region, shock).
        * Specify the desired detection latency (e.g., within 15-30 minutes of arrival at L1).
        * Define target accuracy metrics (e.g., precision, recall, F1-score for event detection; accuracy of boundary identification).
        * Identify necessary input parameters from SWIS-ASPEX (e.g., proton/alpha densities, velocities, temperatures, energy spectra, directional fluxes, energetic particle counts).
        * Determine collaboration protocols with ISRO/PRL for data access and validation.

2.  **Aditya-L1 SWIS-ASPEX Data Acquisition & Management:**
    * **Sub-steps:**
        * Establish secure access to Aditya-L1 SWIS-ASPEX Level 2 data (CDF format).
        * Set up a robust data pipeline for continuous ingestion of real-time and archival data.
        * Implement data storage solutions (e.g., cloud-based or on-premises servers) for large volumes of time-series data.

3.  **Data Pre-processing and Feature Engineering:**
    * **Sub-steps:**
        * **Cleaning:** Handle missing data, outliers, and instrument noise (e.g., using interpolation, Kalman filters, or robust statistics).
        * **Resampling/Synchronization:** Standardize time resolutions across different SWIS-ASPEX data products (e.g., synchronize STEPS 10-min data with SWIS 5-sec data, or resample as needed).
        * **Normalization/Scaling:** Scale all numerical features to a common range (e.g., min-max scaling or z-score normalization) suitable for neural networks.
        * **Feature Construction:** Create composite features (e.g., alpha-to-proton ratio, plasma beta if magnetic field data is used from MAG, ratios of different energy channels) that are known indicators of CME activity.
        * **Directional Data Representation:** Convert directional flux data (from SWIS's 360Â° FOV and STEPS's 6 units) into a format suitable for the AI model (e.g., spherical harmonics coefficients, directional vectors, or directly as 2D/3D tensors representing spatial distributions).

#### Phase 2: "Normal" Solar Wind Characterization and Model Development (Months 4-9)

4.  **"Normal" Solar Wind Dataset Creation:**
    * **Sub-steps:**
        * **Selection:** Curate a large dataset of "quiet" solar wind periods, carefully excluding known CMEs, high-speed streams, or other transient phenomena (potentially using existing solar wind catalogs or manual inspection in early phases). This is the crucial negative-only training set.
        * **Statistical Analysis:** Analyze the statistical properties (mean, variance, correlations) of normal solar wind parameters from SWIS-ASPEX to understand its inherent variability.

5.  **Generative Anomaly Detection (GAD) Model Design & Implementation:**
    * **Sub-steps:**
        * **Architecture Selection:** Research and select the most appropriate GAD architecture (e.g., Variational Autoencoder (VAE), Conditional VAE, Generative Adversarial Network (GAN) for anomaly detection, or even a Transformer-based architecture for sequential data).
        * **Hyperparameter Tuning:** Determine optimal network depth, number of layers, latent space dimensionality, and other hyperparameters.
        * **Initial Training:** Train the GAD model exclusively on the "normal" solar wind dataset. The goal is for the model to accurately reconstruct normal data and generate high reconstruction errors/low likelihoods for anomalous data.

6.  **Physics-Informed Integration:**
    * **Sub-steps:**
        * **Identify Relevant Physics Constraints:** Determine specific physical relationships (e.g., conservation laws across shock transitions, adiabatic invariants for plasma expansion, expected ranges for certain compositional ratios during normal solar wind).
        * **Loss Function Augmentation:** Integrate these physical constraints directly into the GAD model's loss function. For example, add penalty terms that increase if the model's reconstructions violate these physical laws. This helps guide the model to learn physically consistent representations of "normal" solar wind.
        * **Validation of Physics-Informed Learning:** Periodically check if the model's learned latent space and reconstructions adhere better to physical principles compared to a non-physics-informed counterpart.

#### Phase 3: Explainable AI (XAI), Validation, and Deployment (Months 10-18)

7.  **Explainable AI (XAI) Module Development:**
    * **Sub-steps:**
        * **Methodology Selection:** Choose appropriate XAI techniques for interpreting the GAD model's decisions (e.g., LIME, SHAP, integrated gradients for feature importance; attention mechanisms if a Transformer architecture is used).
        * **Feature Attribution Implementation:** Develop algorithms to quantify the contribution of each input parameter (e.g., proton density, alpha flux, specific energy channel, directional bin) to the anomaly score when a CME is detected.
        * **Interpretation Mapping:** Create a mapping between numerical feature attributions and physical interpretations (e.g., "high proton density contribution" maps to "dense plasma consistent with shock sheath").
        * **Visualization:** Design intuitive visualizations for anomaly scores and XAI explanations (e.g., time-series plots highlighting anomalous segments, heatmaps of feature importance).

8.  **Model Training, Validation, and Fine-tuning:**
    * **Sub-steps:**
        * **Anomaly Dataset Creation:** Prepare a dataset of known CME events (including halo CMEs, if available from other L1 missions' data for initial transfer learning, or identified manually in early Aditya-L1 data) to test the anomaly detection capabilities. This dataset is *only* for testing, not training the generative core.
        * **Performance Evaluation:** Evaluate the PIGADE-X system's performance using standard metrics (precision, recall, F1-score for anomaly detection; ROC curves).
        * **Threshold Determination:** Statistically determine optimal thresholds for anomaly scores to balance false positives and false negatives based on operational requirements.
        * **Iterative Refinement:** Iterate on model architecture, hyperparameters, physics constraints, and XAI interpretation based on validation results.

9.  **Real-time Deployment and Alert System Development:**
    * **Sub-steps:**
        * **Containerization:** Package the trained PIGADE-X model and its dependencies into deployable containers (e.g., Docker).
        * **Real-time Data Ingestion:** Develop an interface to continuously ingest real-time SWIS-ASPEX data from the Aditya-L1 ground segment.
        * **Inference Engine:** Implement a low-latency inference engine that processes incoming data segments through the PIGADE-X model.
        * **Alerting System:** Develop an automated alerting system that triggers notifications (e.g., email, dashboard alerts) when an anomaly score exceeds the threshold.
        * **Explanation Output:** Ensure that each alert includes the XAI-generated explanation, detailing the specific particle signatures contributing to the detection.

10. **Continuous Improvement and Maintenance:**
    * **Sub-steps:**
        * **Performance Monitoring:** Continuously monitor the deployed system's performance, logging detections, anomaly scores, and explanations.
        * **Feedback Loop:** Establish a feedback mechanism for space weather scientists to provide input on detected events (confirmations, false alarms, missed events).
        * **Model Retraining/Adaptation:** Periodically retrain the GAD model on updated "normal" solar wind data to adapt to long-term solar cycle variations or instrument aging. Incorporate newly identified CME types or signatures for improving anomaly detection thresholds.
        * **Documentation and Reporting:** Maintain comprehensive documentation of the system, its performance, and detected events. Regularly report findings and improvements.

---

This detailed project plan outlines the key phases and steps required to implement the innovative PIGADE-X system, leveraging Aditya-L1's SWIS-ASPEX data for advanced halo CME detection.
